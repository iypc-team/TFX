{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkwEwr0FQKJW"
   },
   "source": [
    "\n",
    "This notebook contains an examples on how to author and run Python function\n",
    "components within the TFX InteractiveContext and in a locally-orchestrated TFX\n",
    "pipeline.\n",
    "\n",
    "For more context and information, see the [Custom Python function components](https://www.tensorflow.org/tfx/guide/custom_function_component)\n",
    "page on the TFX documentation site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRY0RFJ0VlSV"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from BashColors import C\n",
    "import json, os, sys\n",
    "from os.path import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "print(f'tfx version: {tfx.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvb0SspyqPH4"
   },
   "source": [
    "## Custom Python function components\n",
    "\n",
    "In this section, we will create components from Python functions. We will notbe\n",
    "doing any real ML problem â€” these simple functions are just used to illustrate\n",
    "the Python function component development process.\n",
    "\n",
    "See [Python function based component\n",
    "guide](https://www.tensorflow.org/tfx/guide/custom_function_component)\n",
    "for more documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhYjn9Fj6mdo"
   },
   "outputs": [],
   "source": [
    "%%writefile my_generator.py\n",
    "# Create Python custom components\n",
    "# Write a function that generate some dummy data. This is written to its own Python module file.\n",
    "import os\n",
    "import tensorflow as tf  # Used for writing files.\n",
    "from tfx import v1 as tfx\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.types.experimental.simple_artifacts import Dataset\n",
    "\n",
    "@tfx.dsl.components.component\n",
    "def MyGenerator(data: tfx.dsl.components.OutputArtifact[Dataset]):\n",
    "    \"\"\"Create a file with dummy data in the output artifact.\"\"\"\n",
    "    with tf.io.gfile.GFile(os.path.join(data.uri,\n",
    "                                        'data_file.txt'), 'w') as f:\n",
    "        f.write('Dummy data')\n",
    "        \n",
    "    # Set metadata and ensure that it gets passed to downstream components.\n",
    "    data.set_string_custom_property('my_custom_field', 'my_custom_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtapXcbSqPH6"
   },
   "outputs": [],
   "source": [
    "%%writefile my_consumer.py\n",
    "# write a second component that uses the dummy data produced.\n",
    "# Calculate hash of the data and return it.\n",
    "import hashlib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tfx import v1 as tfx\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.types.experimental.simple_artifacts import Dataset\n",
    "from tfx.types.standard_artifacts import String\n",
    "\n",
    "@tfx.dsl.components.component\n",
    "def MyConsumer(data: tfx.dsl.components.InputArtifact[Dataset],\n",
    "               hash: tfx.dsl.components.OutputArtifact[String],\n",
    "               algorithm: tfx.dsl.components.Parameter[str] = 'sha256'):\n",
    "    \"\"\"Reads the contents of data and calculate.\"\"\"\n",
    "    with tf.io.gfile.GFile(os.path.join(data.uri,\n",
    "                                        'data_file.txt'), 'r') as f:\n",
    "        contents = f.read()\n",
    "    h = hashlib.new(algorithm)\n",
    "    h.update(tf.compat.as_bytes(contents))\n",
    "    hash.value = h.hexdigest()\n",
    "\n",
    "    # Read a custom property from the input artifact and set to the output.\n",
    "    custom_value = data.get_string_custom_property('my_custom_field')\n",
    "    hash.set_string_custom_property('input_custom_field', custom_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIrGHQzFqPII"
   },
   "source": [
    "### Run in-notebook with the InteractiveContext\n",
    "Now, we will demonstrate usage of our new components in the TFX\n",
    "InteractiveContext.\n",
    "\n",
    "For more information on what you can do with the TFX notebook\n",
    "InteractiveContext, see the in-notebook [TFX Keras Component Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j43snQpRqPII"
   },
   "outputs": [],
   "source": [
    "from my_generator import MyGenerator\n",
    "from my_consumer import MyConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1Rf6FCMSnbM"
   },
   "outputs": [],
   "source": [
    "# Construct the InteractiveContext\n",
    "# Create an InteractiveContext using default parameters. This will\n",
    "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
    "# To use your own pipeline root or database, the optional properties\n",
    "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
    "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
    "# notebook.\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxXVtZzdTWg_"
   },
   "source": [
    "#### Run your component interactively with `context.run()`\n",
    "Next, we run our components interactively within the notebook with\n",
    "`context.run()`. Our consumer component uses the outputs of the generator\n",
    "component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfNmI5qULlSA"
   },
   "outputs": [],
   "source": [
    "generator = MyGenerator()\n",
    "context.run(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRxVZIfFLsL4"
   },
   "outputs": [],
   "source": [
    "consumer = MyConsumer(\n",
    "    data=generator.outputs['data'],\n",
    "    algorithm='md5')\n",
    "context.run(consumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO_Ggc4QTo0B"
   },
   "source": [
    "After execution, we can inspect the contents of the \"hash\" output artifact of\n",
    "the consumer component on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4P3Mx_CT0mP"
   },
   "outputs": [],
   "source": [
    "!tail -v {consumer.outputs['hash'].get()[0].uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRosvALKSWe0"
   },
   "source": [
    "That's it, and you've now written and executed your own custom components!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvXKtg17O6mF"
   },
   "source": [
    "### Write a pipeline definition\n",
    "\n",
    "Next, we will author a pipeline using these same components. While using the\n",
    "`InteractiveContext` within a notebook works well for experimentation, defining\n",
    "a pipeline lets you deploy your pipeline on local or remote runners for\n",
    "production usage.\n",
    "\n",
    "Here, we will demonstrate usage of the LocalDagRunner running locally on your\n",
    "machine. For production execution, the Airflow or Kubeflow runners may\n",
    "be more suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft9fbSpnU7C6"
   },
   "source": [
    "#### Construct a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from tfx import v1 as tfx\n",
    "\n",
    "# Select a persistent TFX root directory to store your output artifacts.\n",
    "# For demonstration purposes only, we use a temporary directory.\n",
    "PIPELINE_ROOT = tempfile.mkdtemp()\n",
    "print(f'PIPELINE_ROOT: {C.BIBlue}{PIPELINE_ROOT}{C.ColorOff}')\n",
    "# Select a pipeline name so that multiple runs of the same logical pipeline\n",
    "# can be grouped.\n",
    "PIPELINE_NAME = \"function-based-pipeline\"\n",
    "print(f'PIPELINE_NAME: {C.BIBlue}{PIPELINE_NAME}{C.ColorOff}')\n",
    "# We use a ML Metadata configuration that uses a local SQLite database in\n",
    "# the pipeline root directory. Other backends for ML Metadata are available\n",
    "# for production usage.\n",
    "METADATA_CONNECTION_CONFIG = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
    "    os.path.join(PIPELINE_ROOT, 'metadata.sqlite'))\n",
    "print(f'METADATA_CONNECTION_CONFIG: {C.BIBlue}{METADATA_CONNECTION_CONFIG}{C.ColorOff}')\n",
    "\n",
    "def function_based_pipeline():\n",
    "  # Here, we construct our generator and consumer components in the same way.\n",
    "  generator = MyGenerator()\n",
    "  consumer = MyConsumer(\n",
    "      data=generator.outputs['data'],\n",
    "      algorithm='md5')\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=PIPELINE_NAME,\n",
    "      pipeline_root=PIPELINE_ROOT,\n",
    "      components=[generator, consumer],\n",
    "      metadata_connection_config=METADATA_CONNECTION_CONFIG)\n",
    "\n",
    "my_pipeline = function_based_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mj-Z3cbFWPbK"
   },
   "outputs": [],
   "source": [
    "# Run pipeline with the `LocalDagRunner`\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry4vU3mOWeN1"
   },
   "outputs": [],
   "source": [
    "# Inspect the output artifacts generated by this pipeline execution.\n",
    "!find {PIPELINE_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4CsceadWqHp"
   },
   "source": [
    "You have now written your own custom components and orchestrated their\n",
    "execution on the LocalDagRunner! For next steps, check out additional tutorials\n",
    "and guides on the [TFX website](https://www.tensorflow.org/tfx)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wdeKOEkv1Fe8"
   ],
   "name": "TFX Python function component tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
